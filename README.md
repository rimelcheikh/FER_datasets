# FER_datasets


| Database | Modalities | Size | Model | Description | Available |
| --- | --- | --- | --- | --- | --- |
| FER-2013[10] | Images | 28,709 training 3,589 test | 7 categories s | 48x48 pixel grayscale images of faces | O |
| Oulu-CASIA[14] | Videos | | | Three illumination conditions | O |
| EMOTIC (Kosti et al. 2017) | Images | 23 788 66%M + 34%F11% children11% teenagers78% adults | 26 categories+1âˆ’10 scale VAD | Emotions in Context | |
| KDEF | | | | | |
| CK+(Lucey et al. 2010) | Images | 210 18-50 yo | 7 emotions |
| POM (Park et al. 2014) | Videos | 1000 678M + 322F372 speakers | 7 categories+Valence (-,0,+) | - avg(length) = N(94s,32s)- Facial Action Units + Eye gaze mvts + Head mvts + Approx posture |
| EmoReact (Nojavanasghari et al. 2016) | Videos | 110263 4-14 yo | 7 BE+9 complex E+Neutral + valence | | |
| CAFE (LoBue et al. 2015) | Images | 1192 154 2-8 yo90F + 64M | 6 BE+Neutral | - Posing (open + closed mouth)- Subset A : highly stereotypical- Subset B : emphasize variation 
| AffectNet(Mollahosseini et al. 2019) | Images | 1,000,000 with facial landmarks+450,000 annotated manually | 8 categories+ Valence + arousal |
| MultiPie (Gross et al. 2010) | Images | \&gt;750 000337 subjects | 7 categories | - captured by 15 view and 19illumination conditions |
| MMI (Pantic et al. 2005) | Images+Videos | 740 images 848 videos19 subjects 19-62 | | - both static images and image sequences- frontal and in profile view- single and multiple AU activation |
 

